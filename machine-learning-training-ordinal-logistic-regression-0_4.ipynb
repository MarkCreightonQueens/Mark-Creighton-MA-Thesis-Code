{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Training Ordinal Logistic Regression 0_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fP0ubz0JnXtCRED7Ktruuptra4pCgM4u",
      "authorship_tag": "ABX9TyMr2spP3LA4PYhKWXCBKC5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/MarkCreightonQueens/11112a1e414fd022076fecba787c333e/machine-learning-training-ordinal-logistic-regression-0_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KT76lAf16TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Note: This needs to be ordinal\n",
        "import random as r\n",
        "r.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xKjh1wnV859",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "389590ef-0c97-4b20-e147-8f547c02a494"
      },
      "source": [
        "#installing tools\n",
        "!pip install transformers \n",
        "!pip install wget\n",
        "!pip install tika\n",
        "!pip install ijson"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3efb087cb759eff3a8b7a90c9ade3dabba18ad0fe073d5526e8f6af51350615e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=37038c9b8b9fac8f732ff87af6057daedf3620a769007632c6a52500aae99ec3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika) (47.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (1.24.3)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp36-none-any.whl size=32885 sha256=469902c9b35d476fec3cb37b5bfce6371c90fc19d897a629882dfe42b567bab5\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n",
            "Collecting ijson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/0b/e406ef9de26b2045f2ba689624d1844d1d8ffae991e0d2e792fde256e9ed/ijson-3.1.post0-cp36-cp36m-manylinux1_x86_64.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.7MB/s \n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-iavskzXabH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1ad9195a-d392-45db-f8ff-09c6b3fc5a78"
      },
      "source": [
        "#Importing tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tika import parser\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import wget\n",
        "import urllib.request\n",
        "import re\n",
        "import gzip\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m_8dieYXzdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "924ed085-9a15-4996-9ee5-c0b03c3fff7f"
      },
      "source": [
        "#get GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at:{}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at:/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA3QLek1X1HN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8078f049-abcc-466c-e4f7-3342aa49cdce"
      },
      "source": [
        "#Determining what GPU is available for use\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print ('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else: \n",
        "  print('No GPU available, using CPU instead.')\n",
        "  device = torch.device(\"CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NigBSA7nzbXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.unpack_archive('/content/drive/My Drive/Thesis/yelp_review_full_csv.tgz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urP9qrUcYj2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "098c9677-fa1e-4aa7-a635-8c8bb1c3cd89"
      },
      "source": [
        "#Reading in the CSV. \n",
        "\n",
        "data_train_full = pd.read_csv('/content/yelp_review_full_csv/train.csv', header = None)\n",
        "data_test = pd.read_csv('/content/yelp_review_full_csv/test.csv', header = None)\n",
        "\n",
        "print(data_train_full.shape)\n",
        "print(data_test.shape)\n",
        "\n",
        "#Creating a smaller subset of the training dataset due to computational restrictions\n",
        "data_train_1 = data_train_full[data_train_full[0] == 1].sample(50000, random_state=0)\n",
        "data_train_2 = data_train_full[data_train_full[0] == 2].sample(50000, random_state=0)\n",
        "data_train_3 = data_train_full[data_train_full[0] == 3].sample(50000, random_state=0)\n",
        "data_train_4 = data_train_full[data_train_full[0] == 4].sample(50000, random_state=0)\n",
        "data_train_5 = data_train_full[data_train_full[0] == 5].sample(50000, random_state=0)\n",
        "frames = [data_train_1, data_train_2, data_train_3, data_train_4, data_train_5]\n",
        "data_train = pd.concat(frames)\n",
        "#randomizing the order of the observations\n",
        "data_train = data_train.sample(frac=1, random_state=0)\n",
        "\n",
        "print(data_train[0].unique())\n",
        "print(data_train.shape)\n",
        "\n",
        "#Creating a smaller subset of the training dataset due to computational restrictions\n",
        "data_train_1 = data_train_full[data_train_full[0] == 1].sample(50000, random_state=0)\n",
        "data_train_2 = data_train_full[data_train_full[0] == 2].sample(50000, random_state=0)\n",
        "data_train_3 = data_train_full[data_train_full[0] == 3].sample(50000, random_state=0)\n",
        "data_train_4 = data_train_full[data_train_full[0] == 4].sample(50000, random_state=0)\n",
        "data_train_5 = data_train_full[data_train_full[0] == 5].sample(50000, random_state=0)\n",
        "frames = [data_train_1, data_train_2, data_train_3, data_train_4, data_train_5]\n",
        "data_train = pd.concat(frames)\n",
        "#randomizing the order of the observations\n",
        "data_train = data_train.sample(frac=1, random_state=0)\n",
        "\n",
        "print(data_train[0].unique())\n",
        "print(data_train.shape)\n",
        "\n",
        "#rescaling the ratings\n",
        "data_train[0] = (data_train[0] - 1)\n",
        "data_test[0] = (data_test[0] - 1)\n",
        "\n",
        "print(data_train[0].unique())\n",
        "data_train = data_train.rename(columns={0:'rating',1:'text'})\n",
        "data_test = data_test.rename(columns={0:'rating',1:'text'})\n",
        "data_test\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(650000, 2)\n",
            "(50000, 2)\n",
            "[3 2 4 1 5]\n",
            "(250000, 2)\n",
            "[2 1 3 0 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I got 'new' tires from them and within two wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Don't waste your time.  We had two different p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>All I can say is the worst! We were the only 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>I have been to this restaurant twice and was d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Food was NOT GOOD at all! My husband &amp; I ate h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>0</td>\n",
              "      <td>Just wanted to write a review to chip in with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>4</td>\n",
              "      <td>Great ambience. Great drinks. Great food. I lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>3</td>\n",
              "      <td>I have been to the other Monks locations so I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't go here.  I know you might want to try i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>0</td>\n",
              "      <td>Buffet was recently open after renovation so m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       rating                                               text\n",
              "0           0  I got 'new' tires from them and within two wee...\n",
              "1           0  Don't waste your time.  We had two different p...\n",
              "2           0  All I can say is the worst! We were the only 2...\n",
              "3           0  I have been to this restaurant twice and was d...\n",
              "4           0  Food was NOT GOOD at all! My husband & I ate h...\n",
              "...       ...                                                ...\n",
              "49995       0  Just wanted to write a review to chip in with ...\n",
              "49996       4  Great ambience. Great drinks. Great food. I lo...\n",
              "49997       3  I have been to the other Monks locations so I ...\n",
              "49998       1  Don't go here.  I know you might want to try i...\n",
              "49999       0  Buffet was recently open after renovation so m...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyZeRQiIv0Hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23ace8d9-f284-4a82-af2e-699ee1b4df88"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "OLR_0_4_data = pd.read_csv('/content/drive/My Drive/Thesis/Output_backup.csv')\n",
        "print(OLR_0_4_data.shape)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(data_train['text'])\n",
        "X = cv.transform(data_train['text'])\n",
        "X_test = cv.transform(data_test['text'])\n",
        "OLR_0_4_vector = cv.transform(OLR_0_4_data['Sentences'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42083, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVDfFWNeRKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = pd.Series(data_train['rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFL5Q4jPaI5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "357dc7e6-1d69-4b78-f70f-0621e3aaaf6d"
      },
      "source": [
        "model = LogisticRegression(C=0.25, max_iter = 1024, multi_class='multinomial', solver='newton-cg', fit_intercept=True)\n",
        "model.fit(X, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.25, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1024,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5yl9rAihgzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_test = pd.Series(data_test['rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rjkZT19hgCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c76418-d636-44ab-9347-5be79af45a53"
      },
      "source": [
        "print (\"Final Accuracy:\", accuracy_score(target_test, model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.5727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeTRP7mRahbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9b8ef82a-bd86-492c-c588-ddb86687a908"
      },
      "source": [
        "\n",
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        cv.get_feature_names(), model.coef_[0]\n",
        "    )\n",
        "}\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('poisoning', 1.9741855454665849)\n",
            "('worst', 1.7009662180681777)\n",
            "('horrible', 1.4977398491231892)\n",
            "('zero', 1.4343352854905376)\n",
            "('awful', 1.4267050797911747)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2NhkNkPaqxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "20b56be9-edcd-49ff-8d44-46615f8a4e22"
      },
      "source": [
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('delicious', -1.265281601627145)\n",
            "('excellent', -1.2494072841202832)\n",
            "('fantastic', -1.1763254984690543)\n",
            "('downside', -1.1287660482726314)\n",
            "('awesome', -1.0954335540188778)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVcR2YganbZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfa81be5-5a99-4b7b-ee00-2b4e289592b6"
      },
      "source": [
        "OLR_0_4_results = model.predict(OLR_0_4_vector)\n",
        "print(OLR_0_4_results.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42083,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwMdHYutneD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Thesis/Ordinal Logistic Regression')\n",
        "OLR_0_4_results = pd.DataFrame(data = OLR_0_4_results)\n",
        "outfile = 'OLR_0_4_results.csv'\n",
        "OLR_0_4_results.to_csv(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBcVD4lmElbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "os.chdir('/content/drive/My Drive/Thesis/Ordinal Logistic Regression')\n",
        "filename = 'Ordinal_Logistic_Regression_0_4.p'\n",
        "pickle.dump(model, open(filename,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}