{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Training Multinomial Naive Bayes 0_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ihhuwf2jMYGItAOitT_BcGR8nDDSmB5h",
      "authorship_tag": "ABX9TyNoqRuYTy7lkmFXKr0zH7d3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/MarkCreightonQueens/e68756ec35ed128ec112117a5fe8f5e6/machine-learning-training-multinomial-naive-bayes-0_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KT76lAf16TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as r\n",
        "r.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xKjh1wnV859",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "238b9a3c-03d3-44dc-e433-c5c6892ef203"
      },
      "source": [
        "#installing tools\n",
        "!pip install transformers \n",
        "!pip install wget\n",
        "!pip install tika\n",
        "!pip install ijson"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/25/89050e69ed53c2a3b7f8c67844b3c8339c1192612ba89a172cf85b298948/transformers-3.0.1-py3-none-any.whl (757kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e13672b95ca58eda9b45fd3bcbc50826921a5273fc5faadb91248b6814dcf160\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.1\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=2f46549e8b60869cb9fadb574910872dbc06dbb9e680c399e7fbe72393e6994d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika) (47.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2.9)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp36-none-any.whl size=32885 sha256=a47f0c8598150da2e0a1dc1039894b1b00b5cfb679c66b9aa5477a9717ae6bfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n",
            "Collecting ijson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/0b/e406ef9de26b2045f2ba689624d1844d1d8ffae991e0d2e792fde256e9ed/ijson-3.1.post0-cp36-cp36m-manylinux1_x86_64.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-iavskzXabH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dda01f6d-9d43-4aa1-d1a0-cd51f674fbeb"
      },
      "source": [
        "#Importing tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tika import parser\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import wget\n",
        "import urllib.request\n",
        "import re\n",
        "import gzip\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m_8dieYXzdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3846e761-f784-4989-ea51-ad9166baab26"
      },
      "source": [
        "#get GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at:{}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at:/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA3QLek1X1HN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ebb938a-4ac5-4a74-9f0f-1857a3cf0ce3"
      },
      "source": [
        "#Determining what GPU is available for use\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print ('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else: \n",
        "  print('No GPU available, using CPU instead.')\n",
        "  device = torch.device(\"CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NigBSA7nzbXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.unpack_archive('/content/drive/My Drive/Thesis/yelp_review_full_csv.tgz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urP9qrUcYj2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "0789a704-f3be-44fe-84aa-9c05fcc07bb8"
      },
      "source": [
        "#Reading in the CSV. \n",
        "\n",
        "data_train_full = pd.read_csv('/content/yelp_review_full_csv/train.csv', header = None)\n",
        "data_test = pd.read_csv('/content/yelp_review_full_csv/test.csv', header = None)\n",
        "\n",
        "print(data_train_full.shape)\n",
        "print(data_test.shape)\n",
        "\n",
        "#Creating a smaller subset of the training dataset due to computational restrictions\n",
        "data_train_1 = data_train_full[data_train_full[0] == 1].sample(50000, random_state=0)\n",
        "data_train_2 = data_train_full[data_train_full[0] == 2].sample(50000, random_state=0)\n",
        "data_train_3 = data_train_full[data_train_full[0] == 3].sample(50000, random_state=0)\n",
        "data_train_4 = data_train_full[data_train_full[0] == 4].sample(50000, random_state=0)\n",
        "data_train_5 = data_train_full[data_train_full[0] == 5].sample(50000, random_state=0)\n",
        "frames = [data_train_1, data_train_2, data_train_3, data_train_4, data_train_5]\n",
        "data_train = pd.concat(frames)\n",
        "#randomizing the order of the observations\n",
        "data_train = data_train.sample(frac=1, random_state=0)\n",
        "\n",
        "print(data_train[0].unique())\n",
        "print(data_train.shape)\n",
        "\n",
        "data_train = data_train.rename(columns={0:'rating',1:'text'})\n",
        "data_test = data_test.rename(columns={0:'rating',1:'text'})\n",
        "data_test\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(650000, 2)\n",
            "(50000, 2)\n",
            "[3 2 4 1 5]\n",
            "(250000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I got 'new' tires from them and within two wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't waste your time.  We had two different p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>All I can say is the worst! We were the only 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I have been to this restaurant twice and was d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Food was NOT GOOD at all! My husband &amp; I ate h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>1</td>\n",
              "      <td>Just wanted to write a review to chip in with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>5</td>\n",
              "      <td>Great ambience. Great drinks. Great food. I lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>4</td>\n",
              "      <td>I have been to the other Monks locations so I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>2</td>\n",
              "      <td>Don't go here.  I know you might want to try i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>1</td>\n",
              "      <td>Buffet was recently open after renovation so m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       rating                                               text\n",
              "0           1  I got 'new' tires from them and within two wee...\n",
              "1           1  Don't waste your time.  We had two different p...\n",
              "2           1  All I can say is the worst! We were the only 2...\n",
              "3           1  I have been to this restaurant twice and was d...\n",
              "4           1  Food was NOT GOOD at all! My husband & I ate h...\n",
              "...       ...                                                ...\n",
              "49995       1  Just wanted to write a review to chip in with ...\n",
              "49996       5  Great ambience. Great drinks. Great food. I lo...\n",
              "49997       4  I have been to the other Monks locations so I ...\n",
              "49998       2  Don't go here.  I know you might want to try i...\n",
              "49999       1  Buffet was recently open after renovation so m...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyZeRQiIv0Hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea564b2f-384d-4310-8a4b-d664f1b963c3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "MNB_0_4_data = pd.read_csv('/content/drive/My Drive/Thesis/Output_backup.csv')\n",
        "print(MNB_0_4_data.shape)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(data_train['text'])\n",
        "X = cv.transform(data_train['text'])\n",
        "X_test = cv.transform(data_test['text'])\n",
        "MNB_0_4_vector = cv.transform(MNB_0_4_data['Sentences'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42083, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVDfFWNeRKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = pd.Series(data_train['rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFL5Q4jPaI5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1189af43-6a44-4b50-c767-031f83eb9c70"
      },
      "source": [
        "model = MultinomialNB(alpha = 1, fit_prior = True)\n",
        "model.fit(X, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFI760YLdl-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5yl9rAihgzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_test = pd.Series(data_test['rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rjkZT19hgCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bcbfc69-952b-419f-9481-8460d3e664cd"
      },
      "source": [
        "print (\"Final Accuracy:\", accuracy_score(target_test, model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy: 0.53208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_bn3CAbc6AP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "921a8a95-24a0-421b-ac71-0a344b2926c6"
      },
      "source": [
        "model = MultinomialNB(alpha = 1.0e-10, fit_prior = True)\n",
        "model.fit(X, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1e-10, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l3PHhDAc54e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_test = pd.Series(data_test['rating'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqJqVPRNc5wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbc09802-d2fc-464c-8ff9-cc7bd5f59265"
      },
      "source": [
        "print (\"Final Accuracy without laplace smoothing:\", accuracy_score(target_test, model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy without laplace smoothing: 0.48958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uselQNKGlUoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "832f74d2-b17f-4bc7-bc2c-4173a8fc7704"
      },
      "source": [
        "MNB_0_4_results = model.predict(MNB_0_4_vector)\n",
        "print(MNB_0_4_results.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42083,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIuJudxclXZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Thesis/Multinomial Naive Bayesian/0_4')\n",
        "MNB_0_4_results = pd.DataFrame(data = MNB_0_4_results)\n",
        "outfile = 'MNB_0_4_results.csv'\n",
        "MNB_0_4_results.to_csv(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW09H_GRHHVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "os.chdir('/content/drive/My Drive/Thesis/Multinomial Naive Bayesian/0_4')\n",
        "filename = 'Multinomial_Naive_Bayesian_0_4.p'\n",
        "pickle.dump(model, open(filename,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}